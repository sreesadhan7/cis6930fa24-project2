GitHub Copilot | github.com | Assisted significantly in writing robust function docstrings and completing complex code structures, providing suggestions for efficient coding practices.
Python Standard Library | python.org | Utilized extensively for core functionalities such as file I/O operations, regular expressions (regex), and command-line argument parsing. Modules like sys, argparse, re, glob, and pathlib formed the backbone of the project's functionality.
spaCy | spacy.io | Used as the main natural language processing (NLP) tool to detect and classify named entities such as names, dates, locations, and organizations for the redaction process. spacy's pre-trained models (e.g., en_core_web_md) helped in the accurate detection of sensitive information.
pytest | pytest.org | Employed to create and run unit tests for the redaction functions. Pytest was used to ensure that various functionalities like censoring names, dates, phone numbers, addresses, and custom concepts worked as expected across multiple scenarios.
scikit-learn | scikit-learn.org | Used for feature extraction (e.g., TF-IDF vectorization) and machine learning tasks, including training a Random Forest Classifier, evaluating model performance with metrics like accuracy, precision, recall, and F1-score, and performing hyperparameter tuning.
warnings | python.org | Used to suppress irrelevant warnings (e.g., FutureWarning) during the execution of the program, ensuring cleaner logs and a better user experience.
TfidfVectorizer (part of scikit-learn) | scikit-learn | Specifically highlighted as the core feature extraction technique, transforming text data into numeric vectors for use in the Random Forest Classifier.